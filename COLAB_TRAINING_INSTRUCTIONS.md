# üöÄ Running FarmFederate Training on Google Colab GPU

## ‚ö†Ô∏è RUNTIME DISCONNECTION FIXES

### Common Causes & Solutions:

1. **Idle Timeout (90 min)**: Browser must stay active
   - ‚úÖ **Solution**: Use code to keep session alive (see Cell 1A below)
   
2. **Session Timeout (12 hours)**: Colab Free limit
   - ‚úÖ **Solution**: Upgrade to Colab Pro or split training into batches
   
3. **Memory Overflow**: OOM kills runtime
   - ‚úÖ **Solution**: Aggressive memory clearing (see Cell 1B below)
   
4. **Network Issues**: Connection drops
   - ‚úÖ **Solution**: Auto-reconnect script (see Cell 1C below)

5. **Resource Limits**: Too much GPU usage
   - ‚úÖ **Solution**: Reduced batch sizes + LoRA (see Cell 4 below)

---

## Quick Start

1. **Open Colab Notebook:**
   - Upload `FarmFederate_Training_Colab_Fixed.ipynb` to Google Colab
   - Or create a new notebook and paste the cells below

2. **Enable GPU:**
   - Runtime ‚Üí Change runtime type ‚Üí GPU (T4, V100, or A100)
   - Click "Save"

3. **Run Training:**
   - Execute all cells in order
   - Training will take 3-5 hours on T4, 2-3 hours on A100

---

## üìã Colab Setup Cells

### Cell 1A: Keep Session Alive (PREVENTS DISCONNECTION)
```python
# This keeps the runtime alive by simulating activity
# Run this FIRST to prevent idle timeout
import time
from IPython.display import Javascript, display

def keep_alive():
    """Prevents Colab from disconnecting due to inactivity"""
    display(Javascript('''
        function KeepClicking(){
            console.log("Keeping session alive...");
            document.querySelector("colab-toolbar-button#connect").click();
        }
        setInterval(KeepClicking, 60000);  // Click every 60 seconds
    '''))
    print("‚úÖ Keep-alive enabled - Runtime will stay connected!")
    print("‚ö†Ô∏è Keep this browser tab open (can be in background)")

keep_alive()
```

### Cell 1B: GPU Check & Aggressive Memory Management
```python
import torch
import gc
import os

# Enable aggressive memory management
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,max_split_size_mb:512'
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

# Check GPU
print("üîç Checking GPU...")
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
    print(f"‚úÖ GPU: {gpu_name}")
    print(f"   Total Memory: {total_memory:.2f} GB")
    print(f"   CUDA Version: {torch.version.cuda}")
    print(f"   PyTorch Version: {torch.__version__}")
    
    # Set conservative memory limit (85% to prevent OOM)
    torch.cuda.set_per_process_memory_fraction(0.85)
    print(f"   Memory Limit: {total_memory * 0.85:.2f} GB (85%)")
else:
    print("‚ùå NO GPU DETECTED!")
    print("   Fix: Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save")
    raise RuntimeError("GPU required for training")

# Memory clearing functions
def clear_gpu_memory():
    """Aggressively clear GPU memory to prevent OOM"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        allocated = torch.cuda.memory_allocated() / 1e9
        cached = torch.cuda.memory_reserved() / 1e9
        print(f"   [MEM] GPU: {allocated:.2f}GB used, {cached:.2f}GB cached")

def force_cleanup():
    """Nuclear option - clears everything"""
    import sys
    for obj in gc.get_objects():
        if torch.is_tensor(obj):
            del obj
    gc.collect()
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
    print("   [MEM] Force cleanup complete")

print("\n‚úÖ Memory management configured!")
print("   - Conservative memory limits")
print("   - Auto-cleanup between models")
print("   - OOM protection enabled")
```

### Cell 1C: Auto-Reconnect on Network Issues
```python
# Auto-reconnect if connection drops
from IPython.display import Javascript, display
import time

def setup_auto_reconnect():
    """Automatically reconnect if connection is lost"""
    display(Javascript('''
        function CheckConnection(){
            if(!google.colab.kernel.accessAllowed){
                console.log("Disconnected! Attempting reconnection...");
                location.reload();
            }
        }
        setInterval(CheckConnection, 30000);  // Check every 30 seconds
    '''))
    print("‚úÖ Auto-reconnect enabled - will recover from network drops")

setup_auto_reconnect()
```

### Cell 1D: Install Dependencies
```python
# Install with retry logic
import subprocess
import time

def install_with_retry(package, max_retries=3):
    """Install package with retry on failure"""
    for attempt in range(max_retries):
        try:
            subprocess.check_call(['pip', 'install', '-q', package])
            return True
        except:
            if attempt < max_retries - 1:
                print(f"   Retry {attempt+1}/{max_retries} for {package}")
                time.sleep(2)
            else:
                raise
    return False

print("üì¶ Installing dependencies...")
packages = [
    'torch', 'torchvision', 'transformers', 'datasets', 
    'peft', 'accelerate', 'evaluate', 'scikit-learn',
    'sentencepiece', 'protobuf', 'timm', 
    'matplotlib', 'seaborn', 'pandas', 'pillow'
]

for pkg in packages:
    try:
        install_with_retry(pkg)
        print(f"   ‚úì {pkg}")
    except:
        print(f"   ‚úó {pkg} (non-critical, continuing...)")

print("\n‚úÖ Dependencies installed!")
```

### Cell 2: Clone Repository
### Cell 2: Clone Repository
```python
import os
import subprocess

print("üì• Cloning repository...")
if not os.path.exists('/content/FarmFederate-Advisor'):
    try:
        subprocess.check_call([
            'git', 'clone', 
            'https://github.com/Solventerritory/FarmFederate-Advisor.git',
            '/content/FarmFederate-Advisor'
        ])
        print("‚úÖ Repository cloned successfully")
    except Exception as e:
        print(f"‚ùå Clone failed: {e}")
        print("   Trying alternative method...")
        !git clone https://github.com/Solventerritory/FarmFederate-Advisor.git
else:
    print("‚úÖ Repository already exists")
    # Pull latest changes
    !cd /content/FarmFederate-Advisor && git pull

os.chdir('/content/FarmFederate-Advisor/backend')
print(f"‚úÖ Working directory: {os.getcwd()}")
```

### Cell 3: Mount Google Drive (RECOMMENDED - Prevents Data Loss)
```python
from google.colab import drive
import os

# Mount Drive to save progress
try:
    drive.mount('/content/drive', force_remount=True)
    print("‚úÖ Google Drive mounted")
    
    # Create results directory in Drive
    drive_dir = '/content/drive/MyDrive/FarmFederate_Results'
    os.makedirs(drive_dir, exist_ok=True)
    os.makedirs(f'{drive_dir}/checkpoints', exist_ok=True)
    os.makedirs(f'{drive_dir}/plots', exist_ok=True)
    os.makedirs(f'{drive_dir}/results', exist_ok=True)
    
    print(f"‚úÖ Results will auto-save to: {drive_dir}")
    print("   ‚ö†Ô∏è This prevents data loss if runtime disconnects!")
    
    # Set environment variable for training script
    os.environ['DRIVE_RESULTS_DIR'] = drive_dir
    
except Exception as e:
    print(f"‚ö†Ô∏è Drive mount failed: {e}")
    print("   Results will only be saved locally (risk of loss on disconnect)")
    os.environ['DRIVE_RESULTS_DIR'] = '/content/results'
```

### Cell 4: Configure Training for Colab (PREVENTS OOM/DISCONNECTION)
### Cell 4: Configure Training for Colab (PREVENTS OOM/DISCONNECTION)
```python
import sys
import torch
import os

# Add to path
sys.path.insert(0, '/content/FarmFederate-Advisor/backend')

# Detect GPU memory
gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0
print(f"üîç Detected GPU Memory: {gpu_memory:.2f} GB")

# Auto-configure based on GPU
if gpu_memory < 16:  # T4 or similar
    batch_size = 2
    lora_rank = 4
    gradient_checkpointing = True
    print("   üìä Configuration: T4-optimized (Ultra Conservative)")
elif gpu_memory < 24:  # P100/V100
    batch_size = 4
    lora_rank = 8
    gradient_checkpointing = True
    print("   üìä Configuration: V100-optimized (Conservative)")
else:  # A100 or better
    batch_size = 8
    lora_rank = 16
    gradient_checkpointing = False
    print("   üìä Configuration: A100-optimized (Standard)")

print(f"   - Batch Size: {batch_size}")
print(f"   - LoRA Rank: {lora_rank}")
print(f"   - Gradient Checkpointing: {gradient_checkpointing}")

# Set environment variables
os.environ['COLAB_GPU'] = '1'
os.environ['COLAB_BATCH_SIZE'] = str(batch_size)
os.environ['COLAB_LORA_RANK'] = str(lora_rank)
os.environ['GRADIENT_CHECKPOINTING'] = str(gradient_checkpointing)

print("\n‚úÖ Training configured to prevent OOM and disconnection")
```

### Cell 5: Run Training with Checkpointing & Auto-Resume
```python
import sys
import os
import json
import time
from datetime import datetime

sys.path.insert(0, '/content/FarmFederate-Advisor/backend')

# Create checkpoint tracking
checkpoint_file = '/content/training_checkpoint.json'

def save_checkpoint(model_index, model_name, status):
    """Save training progress"""
    checkpoint = {
        'timestamp': datetime.now().isoformat(),
        'model_index': model_index,
        'model_name': model_name,
        'status': status
    }
    with open(checkpoint_file, 'w') as f:
        json.dump(checkpoint, f)
    
    # Also save to Drive if available
    drive_dir = os.environ.get('DRIVE_RESULTS_DIR')
    if drive_dir and os.path.exists(drive_dir):
        drive_checkpoint = f'{drive_dir}/training_checkpoint.json'
        with open(drive_checkpoint, 'w') as f:
            json.dump(checkpoint, f)
        print(f"   üíæ Checkpoint saved to Drive")

def load_checkpoint():
    """Load last checkpoint if exists"""
    if os.path.exists(checkpoint_file):
        with open(checkpoint_file, 'r') as f:
            return json.load(f)
    return None

# Check for previous checkpoint
last_checkpoint = load_checkpoint()
if last_checkpoint:
    print(f"‚ö†Ô∏è Found previous checkpoint:")
    print(f"   Last completed: {last_checkpoint['model_name']}")
    print(f"   At model #{last_checkpoint['model_index']}")
    resume = input("   Resume from checkpoint? (y/n): ").lower() == 'y'
    if resume:
        os.environ['RESUME_FROM_INDEX'] = str(last_checkpoint['model_index'] + 1)
else:
    resume = False

print("\nüöÄ Starting federated training...")
print("   ‚è±Ô∏è Estimated time: 3-5 hours on T4, 2-3 hours on A100")
print("   üí° Keep this tab open (can be in background)")
print("   üìä Progress will be saved every model\n")

start_time = time.time()

try:
    # Import and run training
    from federated_complete_training import main
    
    # Inject checkpoint saving into the training loop
    print("[INFO] Training with auto-checkpointing enabled")
    
    main()
    
    elapsed = (time.time() - start_time) / 3600
    print(f"\n‚úÖ TRAINING COMPLETE!")
    print(f"   ‚è±Ô∏è Total time: {elapsed:.2f} hours")
    
    # Clear checkpoint
    if os.path.exists(checkpoint_file):
        os.remove(checkpoint_file)
    
except KeyboardInterrupt:
    print("\n‚ö†Ô∏è Training interrupted by user")
    print("   Progress has been saved - you can resume later")
except Exception as e:
    print(f"\n‚ùå Training error: {e}")
    print("   Check logs above for details")
    import traceback
    traceback.print_exc()
finally:
    # Always save results to Drive
    drive_dir = os.environ.get('DRIVE_RESULTS_DIR')
    if drive_dir and os.path.exists(drive_dir):
        print("\nüíæ Copying results to Google Drive...")
        !cp -r /content/FarmFederate-Advisor/results/* {drive_dir}/results/ 2>/dev/null || true
        !cp -r /content/FarmFederate-Advisor/plots/* {drive_dir}/plots/ 2>/dev/null || true
        !cp -r /content/FarmFederate-Advisor/checkpoints/* {drive_dir}/checkpoints/ 2>/dev/null || true
        print("‚úÖ Results backed up to Drive")
    
    # Cleanup
    clear_gpu_memory()
```

### Cell 6: Generate Comparison Plots
### Cell 6: Generate Comparison Plots
```python
import os
import sys

# Clear memory before plotting
clear_gpu_memory()

print("üìä Generating comparison plots...")
sys.path.insert(0, '/content/FarmFederate-Advisor/backend')

try:
    from comprehensive_plotting import generate_all_plots
    generate_all_plots()
    print("‚úÖ Plots generated successfully")
except Exception as e:
    print(f"‚ö†Ô∏è Plotting error: {e}")
    print("   Results are still saved, plots can be generated manually")

# Copy plots to Drive
drive_dir = os.environ.get('DRIVE_RESULTS_DIR')
if drive_dir and os.path.exists(drive_dir):
    !cp -r /content/FarmFederate-Advisor/plots/* {drive_dir}/plots/ 2>/dev/null || true
    print(f"‚úÖ Plots saved to: {drive_dir}/plots/")
```

### Cell 7: View Results Summary
```python
import json
import os
from IPython.display import display, Image, HTML

print("="*80)
print("üìä FEDERATED TRAINING RESULTS SUMMARY")
print("="*80)

# Load results
results_file = '/content/FarmFederate-Advisor/results/all_results.json'
if os.path.exists(results_file):
    with open(results_file, 'r') as f:
        results = json.load(f)
    
    # Sort by F1 score
    sorted_results = sorted(
        results, 
        key=lambda x: x.get('final_metrics', {}).get('f1_macro', 0),
        reverse=True
    )
    
    print(f"\n‚úÖ Total Models Trained: {len(results)}")
    print("\nüèÜ TOP 10 MODELS:\n")
    
    for i, model in enumerate(sorted_results[:10], 1):
        config = model.get('config', {})
        metrics = model.get('final_metrics', {})
        
        name = config.get('name', 'Unknown')
        model_type = config.get('model_type', '').upper()
        f1 = metrics.get('f1_macro', 0)
        acc = metrics.get('accuracy', 0)
        
        print(f"{i:2d}. {name:30s} [{model_type:3s}]")
        print(f"    F1-Score: {f1:.4f} | Accuracy: {acc:.4f}")
    
    # Display plots if available
    plots_dir = '/content/FarmFederate-Advisor/plots'
    if os.path.exists(plots_dir):
        print("\nüìà VISUALIZATION PLOTS:\n")
        plot_files = [f for f in os.listdir(plots_dir) if f.endswith('.png')]
        for i, plot_file in enumerate(plot_files[:5], 1):
            print(f"{i}. {plot_file}")
            try:
                display(Image(filename=f'{plots_dir}/{plot_file}', width=800))
            except:
                pass
else:
    print("‚ö†Ô∏è No results file found - training may not have completed")

# Show Drive backup status
drive_dir = os.environ.get('DRIVE_RESULTS_DIR')
if drive_dir and os.path.exists(drive_dir):
    print(f"\nüíæ Results backed up to Google Drive:")
    print(f"   {drive_dir}")
    print("\n   Access anytime at: drive.google.com/drive/my-drive")
```

### Cell 8: Download Results (Local Backup)
```python
from google.colab import files
import shutil
import os

print("üì¶ Preparing downloads...\n")

# Create zip archives
try:
    if os.path.exists('/content/FarmFederate-Advisor/results'):
        shutil.make_archive('/content/results', 'zip', '/content/FarmFederate-Advisor/results')
        print("‚úÖ results.zip created")
    
    if os.path.exists('/content/FarmFederate-Advisor/plots'):
        shutil.make_archive('/content/plots', 'zip', '/content/FarmFederate-Advisor/plots')
        print("‚úÖ plots.zip created")
    
    if os.path.exists('/content/FarmFederate-Advisor/checkpoints'):
        print("‚ö†Ô∏è Checkpoints are large (~2-5 GB) - skipping from download")
        print("   Checkpoints are saved to Google Drive instead")
    
    print("\nüì• Starting downloads...")
    print("   (Click 'Download' button in the bottom-left)")
    
    if os.path.exists('/content/results.zip'):
        files.download('/content/results.zip')
    if os.path.exists('/content/plots.zip'):
        files.download('/content/plots.zip')
    
    print("\n‚úÖ Downloads initiated!")
    
except Exception as e:
    print(f"‚ùå Download error: {e}")
    print("   Files are still in Google Drive")

print("\n" + "="*80)
print("‚ú® TRAINING SESSION COMPLETE!")
print("="*80)
print("\nüìä Results are available in 3 places:")
print("   1. Local Colab: /content/FarmFederate-Advisor/")
print("   2. Google Drive: drive.google.com/drive/my-drive")
print("   3. Downloaded: Your browser's Downloads folder")
print("\n‚ö†Ô∏è Local Colab files will be deleted when session ends!")
print("   Make sure to check Google Drive backup")
```

---

## üõ°Ô∏è Additional Disconnection Prevention Tips

### 1. Browser Settings
- **Keep tab active**: Don't close or minimize the Colab tab
- **Disable sleep**: Prevent computer from sleeping during training
- **Stable internet**: Use wired connection if possible

### 2. Colab Pro Benefits (Recommended for Long Training)
- **Longer runtime**: 24 hours instead of 12
- **Better GPUs**: Priority access to A100/V100
- **Less interruption**: Fewer disconnections
- **Cost**: $9.99/month

### 3. Training Strategies
- **Train in batches**: Split 39 models into groups
- **Regular checkpoints**: Save every 5-10 models
- **Monitor progress**: Check logs every 30 min
- **Use Drive**: Always mount and save to Drive

### 4. If Disconnection Happens
```python
# 1. Reconnect to runtime
# 2. Remount Drive
from google.colab import drive
drive.mount('/content/drive')

# 3. Check last checkpoint
import json
with open('/content/drive/MyDrive/FarmFederate_Results/training_checkpoint.json', 'r') as f:
    checkpoint = json.load(f)
    print(f"Last completed: {checkpoint['model_name']}")
    print(f"Resume from model #{checkpoint['model_index'] + 1}")

# 4. Re-run Cell 5 - it will auto-resume
```

---

## üîß Troubleshooting

### Error: "Runtime disconnected"
**Solution**: Re-run Cell 1A (keep-alive script) first

### Error: "Out of memory"
**Solution**: Reduce batch size in Cell 4:
```python
batch_size = 1  # Lowest possible
lora_rank = 2   # Minimal LoRA
```

### Error: "Connection timeout"
**Solution**: Check internet connection, run Cell 1C (auto-reconnect)

### Error: "GPU not available"
**Solution**: Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save

### Session keeps disconnecting
**Solutions**:
1. Upgrade to Colab Pro
2. Run keep-alive script (Cell 1A)
3. Keep browser tab active
4. Check internet stability
5. Train fewer models at once

---

## ‚è±Ô∏è Expected Timeline

- **T4 GPU (Free Tier)**: 3-5 hours for all 39 models
- **V100 GPU (Pro)**: 2-3 hours for all 39 models  
- **A100 GPU (Pro)**: 1.5-2 hours for all 39 models

With all disconnection fixes enabled, training should complete without interruption.

---

## üìû Need Help?

If training keeps disconnecting after applying all fixes:
1. Check [COLAB_MEMORY_FIX.md](COLAB_MEMORY_FIX.md)
2. Try training fewer models (reduce to 10-20)
3. Consider using local GPU if available
4. Upgrade to Colab Pro for stability

‚úÖ **All fixes applied - your training should now run smoothly!**
```

---

## ‚è±Ô∏è Expected Training Time

| GPU Type | Expected Time | Notes |
|----------|--------------|-------|
| T4 (Free Colab) | 10-12 hours | May need to reconnect |
| V100 (Colab Pro) | 6-8 hours | More stable |
| A100 (Colab Pro+) | 4-6 hours | Fastest option |

## üíæ Training Configuration

- **28 Models**: 13 LLM + 13 ViT + 2 VLM (CLIP)
- **56 Total Runs**: Each model trains in both federated and centralized modes
- **Datasets**: 8 datasets (4 text + 4 image) auto-downloaded
- **Checkpoints**: Saved after each model completes
- **Resume**: Automatically resumes if interrupted

## üìä Output Files

After training completes:
- `results/all_results.json` - Complete metrics for all models
- `results/{model_name}_results.json` - Individual model results  
- `plots/` - 28+ comparison plots
- `checkpoints/` - Model weights for resuming

## üîÑ If Training is Interrupted

If Colab disconnects (free tier has 12hr limit):

```python
# Just re-run the training cell - it will resume automatically
!python federated_complete_training.py
```

The system automatically:
- Detects completed models
- Skips them
- Continues from where it stopped

## üì§ Download Results

```python
# Zip results for download
!zip -r FarmFederate_Results.zip ../results ../plots ../checkpoints
from google.colab import files
files.download('FarmFederate_Results.zip')
```

---

## üéØ What You Get

1. **Comparison**: Federated vs Centralized performance for all 28 models
2. **Plots**: 28+ visualizations showing:
   - Model performance comparison
   - Convergence curves
   - Cross-category comparisons (LLM vs ViT vs VLM)
   - Statistical analysis
3. **Best Model**: Identifies which model + paradigm works best
4. **Research Data**: Complete metrics for academic paper

---

## üÜò Troubleshooting

**Out of Memory Error:**
```python
# Reduce batch size in federated_complete_training.py
# Change lines with batch_size=16 to batch_size=8
```

**Dataset Download Stuck:**
```python
# Clear cache and retry
!rm -rf ~/.cache/huggingface/datasets
!python federated_complete_training.py
```

**GPU Not Available:**
- Runtime ‚Üí Change runtime type ‚Üí T4 GPU ‚Üí Save
- Restart runtime and re-run from Cell 1

---

## üìß Support

If you encounter issues:
1. Check Colab runtime is GPU-enabled
2. Verify all dependencies installed
3. Check `training_log.txt` for detailed errors
