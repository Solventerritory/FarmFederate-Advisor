{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c659a9b8",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Solventerritory/FarmFederate-Advisor/blob/feature/multimodal-work/colab_run_farmfederate.ipynb)\n",
    "\n",
    "**Open in Colab** — click the badge above to open this notebook directly in Colab. After opening, set Runtime → Change runtime type → GPU and run cells in order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Memory Demo (run after setup)\n",
    "# This short note points you to the demo cell that exercises the new Qdrant memory layer.\n",
    "# 1) Run the **One-Click Setup & Dry-Run** cell to install required packages (qdrant-client, sentence-transformers, ...)\n",
    "# 2) Run cell \"13) Quick RAG / Qdrant test snippet (optional)\" to validate Qdrant client availability\n",
    "# 3) Run cell \"13b) DEMO: FarmMemoryAgent store + retrieve demo\" to store sample reports and retrieve top-3 similar entries for a demo farm.\n",
    "# The demo uses an in-memory Qdrant instance so no external credentials are required.\n",
    "print('Memory Demo: run cell \"13b) DEMO: FarmMemoryAgent store + retrieve demo\" after setup cell')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538c19c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-CLICK SETUP & DRY-RUN (run this cell)\n",
    "# This cell will:\n",
    "#  - install core packages (quietly),\n",
    "#  - optionally mount Google Drive,\n",
    "#  - prompt for HF_TOKEN and GITHUB_TOKEN,\n",
    "#  - allow you to upload kaggle.json,\n",
    "#  - set RUN_ON_COLAB=1 and DRY_RUN=1 and run a safe dry-run validation of the main script.\n",
    "\n",
    "import os, sys, getpass, subprocess\n",
    "print('One-Click Setup starting...')\n",
    "\n",
    "# 1) Install core packages (silent)\n",
    "pkgs = ['qdrant-client','sentence-transformers','transformers','datasets','kaggle','huggingface_hub','torch','torchvision','scikit-learn','imgaug']\n",
    "missing = []\n",
    "for p in pkgs:\n",
    "    try:\n",
    "        __import__(p if p != 'scikit-learn' else 'sklearn')\n",
    "    except Exception:\n",
    "        missing.append(p)\n",
    "if missing:\n",
    "    print('Installing:', missing)\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q'] + missing)\n",
    "else:\n",
    "    print('All required packages already installed')\n",
    "\n",
    "# 2) Optional: mount Google Drive\n",
    "try:\n",
    "    from google.colab import drive, files\n",
    "    mount = input('Mount Google Drive to persist results? (Y/n): ').strip().lower() or 'y'\n",
    "    if mount == 'y':\n",
    "        drive.mount('/content/drive')\n",
    "        os.makedirs('/content/drive/MyDrive/FarmFederate-results', exist_ok=True)\n",
    "        print('Drive mounted: /content/drive/MyDrive/FarmFederate-results')\n",
    "except Exception:\n",
    "    print('Not running in Colab or Drive API not available; skipping Drive mount')\n",
    "\n",
    "# 3) Upload kaggle.json (optional)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print('\\nUpload kaggle.json now (or press Enter to skip)')\n",
    "    uploaded = files.upload()\n",
    "    if uploaded:\n",
    "        kaggle_dir = '/root/.kaggle'\n",
    "        os.makedirs(kaggle_dir, exist_ok=True)\n",
    "        for fn, data in uploaded.items():\n",
    "            open(os.path.join(kaggle_dir, 'kaggle.json'), 'wb').write(data)\n",
    "        try:\n",
    "            os.chmod(os.path.join(kaggle_dir, 'kaggle.json'), 0o600)\n",
    "        except Exception:\n",
    "            pass\n",
    "        print('Saved kaggle.json to ~/.kaggle/kaggle.json')\n",
    "    else:\n",
    "        print('No kaggle.json uploaded')\n",
    "except Exception:\n",
    "    print('Upload not available (not in Colab). Use env vars KAGGLE_USERNAME/KAGGLE_KEY instead.')\n",
    "\n",
    "# 4) Prompt for tokens\n",
    "hf = getpass.getpass('Enter HF_TOKEN (leave blank to skip): ')\n",
    "if hf:\n",
    "    os.environ['HF_TOKEN'] = hf\n",
    "    print('HF_TOKEN set')\n",
    "gh = getpass.getpass('Enter GITHUB_TOKEN (leave blank to skip): ')\n",
    "if gh:\n",
    "    os.environ['GITHUB_TOKEN'] = gh\n",
    "    print('GITHUB_TOKEN set')\n",
    "\n",
    "# 5) Run dry-run validation\n",
    "os.environ['RUN_ON_COLAB'] = '1'\n",
    "os.environ['DRY_RUN'] = '1'\n",
    "print('\\nRunning dry-run validation (DRY_RUN=1) — this will not download large datasets')\n",
    "subprocess.run([sys.executable, '-u', 'FarmFederate_Kaggle_Complete.py', '--dry-run'], check=False)\n",
    "print('\\nDry-run completed. Inspect results/dataset_discovery_manifest.json and results/run_status.json for any issues.')\n",
    "\n",
    "# 6) Offer to proceed to full run\n",
    "cont = input('\\nProceed to full run now (this will download datasets and may take a long time)? (y/N): ').strip().lower() or 'n'\n",
    "if cont == 'y':\n",
    "    os.environ['DRY_RUN'] = '0'\n",
    "    print('Starting full run (logs will stream to results/colab_full_run.log)')\n",
    "    subprocess.run([sys.executable, '-u', 'FarmFederate_Kaggle_Complete.py'], check=False)\n",
    "else:\n",
    "    print('Full run skipped. You can run the full run later by setting DRY_RUN=0 and executing the script')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce4c5c4",
   "metadata": {},
   "source": [
    "# FarmFederate Colab Launcher & README\n",
    "\n",
    "**Quick start (recommended):**\n",
    "1. Open this notebook in Colab: \n",
    "   https://colab.research.google.com/github/Solventerritory/FarmFederate-Advisor/blob/feature/multimodal-work/colab_run_farmfederate.ipynb\n",
    "2. Runtime → Change runtime type → select GPU (T4 or P100 recommended).\n",
    "3. Run the **One-Click Setup & Dry-Run** cell (next). It will install packages, prompt for tokens, optionally mount Drive, and run a safe DRY-RUN of the pipeline.\n",
    "\n",
    "Important notes:\n",
    "- Provide `kaggle.json` (upload) or set `KAGGLE_USERNAME` and `KAGGLE_KEY` env vars for Kaggle downloads.\n",
    "- Provide `HF_TOKEN` (Hugging Face) and `GITHUB_TOKEN` if you need access to private HF/GitHub datasets.\n",
    "- The full run may be long and download many datasets; use `--max-files` / `--max-text` limits or run a subset first.\n",
    "\n",
    "If you want me to create a public Colab share link (hosted notebook) or add a short README file to the repo, say so and I'll add it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3267fe",
   "metadata": {},
   "source": [
    "# FarmFederate — Colab Run Notebook\n",
    "\n",
    "This notebook prepares a Colab environment to run `FarmFederate_Kaggle_Complete.py` end-to-end (dry-run validation, full run, ingestion, RAG test, and result sync).\n",
    "\n",
    "Important:\n",
    "- Use a GPU runtime (Runtime → Change runtime type → GPU).\n",
    "- Upload `kaggle.json` or set `KAGGLE_USERNAME`/`KAGGLE_KEY` before running ingestion steps.\n",
    "- Provide `HF_TOKEN` and `GITHUB_TOKEN` when prompted for private HuggingFace/GitHub access.\n",
    "\n",
    "Follow cells in order and inspect logs in `results/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e5807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Runtime & GPU check\n",
    "import sys, platform, subprocess, os\n",
    "import torch\n",
    "print('Python', sys.version)\n",
    "print('Platform', platform.platform())\n",
    "print('Torch', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        !nvidia-smi\n",
    "    except Exception as e:\n",
    "        print('nvidia-smi failed:', e)\n",
    "# Memory / disk\n",
    "try:\n",
    "    import psutil\n",
    "    vm = psutil.virtual_memory()\n",
    "    print(f'RAM: {vm.total/1e9:.1f} GB, Available: {vm.available/1e9:.1f} GB')\n",
    "except Exception:\n",
    "    pass\n",
    "print('Disk usage:')\n",
    "!df -h | sed -n '1,10p'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e13e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Install Python dependencies (run once)\n",
    "# Installs are quiet to keep output compact. Adjust packages as needed.\n",
    "!pip install -q qdrant-client sentence-transformers transformers datasets kaggle huggingface_hub torch torchvision scikit-learn imgaug\n",
    "print('Installed core packages (or they were already present).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4531b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Mount Google Drive (optional)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    drive_root = '/content/drive/MyDrive/FarmFederate-results'\n",
    "    import os\n",
    "    os.makedirs(drive_root, exist_ok=True)\n",
    "    print('Drive mounted, results will be copied to', drive_root)\n",
    "except Exception as e:\n",
    "    print('Google Drive not available or not running in Colab:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Clone repository & checkout branch\n",
    "import os\n",
    "if not os.path.exists('FarmFederate-Advisor'):\n",
    "    !git clone https://github.com/Solventerritory/FarmFederate-Advisor.git\n",
    "%cd FarmFederate-Advisor\n",
    "!git fetch --all --quiet\n",
    "!git checkout feature/multimodal-work || true\n",
    "!git pull --quiet\n",
    "# Verify the main script exists\n",
    "print('\\nListing root files:')\n",
    "!ls -la | sed -n '1,200p'\n",
    "print('\\nChecking for FarmFederate_Kaggle_Complete.py:')\n",
    "!ls -la FarmFederate_Kaggle_Complete.py || true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef631c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Upload kaggle.json or set Kaggle env vars\n",
    "# Use the file upload UI to securely set kaggle.json when running interactively in Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print('Upload kaggle.json now (or cancel to use env vars)')\n",
    "    uploaded = files.upload()\n",
    "    if uploaded:\n",
    "        kaggle_dir = '/root/.kaggle'\n",
    "        import os\n",
    "        os.makedirs(kaggle_dir, exist_ok=True)\n",
    "        for fn, data in uploaded.items():\n",
    "            open(os.path.join(kaggle_dir, 'kaggle.json'), 'wb').write(data)\n",
    "        try:\n",
    "            os.chmod(os.path.join(kaggle_dir, 'kaggle.json'), 0o600)\n",
    "        except Exception:\n",
    "            pass\n",
    "        print('Saved kaggle.json to ~/.kaggle/kaggle.json')\n",
    "    else:\n",
    "        print('No kaggle.json uploaded. You can set KAGGLE_USERNAME and KAGGLE_KEY as env vars.')\n",
    "except Exception as e:\n",
    "    print('files.upload not available (not in Colab). Set KAGGLE_USERNAME/KAGGLE_KEY env vars manually.')\n",
    "\n",
    "# Example: set env vars manually (uncomment to use)\n",
    "# import os\n",
    "# os.environ['KAGGLE_USERNAME'] = 'YOUR_USERNAME'\n",
    "# os.environ['KAGGLE_KEY'] = 'YOUR_KEY'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448d8a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Securely set HF_TOKEN and GITHUB_TOKEN (interactive)\n",
    "import os, getpass\n",
    "hf = getpass.getpass('Enter HuggingFace HF_TOKEN (leave blank to skip): ')\n",
    "if hf:\n",
    "    os.environ['HF_TOKEN'] = hf\n",
    "    print('HF_TOKEN set')\n",
    "gh = getpass.getpass('Enter GITHUB_TOKEN (leave blank to skip): ')\n",
    "if gh:\n",
    "    os.environ['GITHUB_TOKEN'] = gh\n",
    "    print('GITHUB_TOKEN set')\n",
    "print('\\nNote: these values are stored in the kernel environment only; do not print tokens.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b504fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Confirm FarmFederate_Kaggle_Complete.py is ready\n",
    "import os\n",
    "script = 'FarmFederate_Kaggle_Complete.py'\n",
    "if not os.path.exists(script):\n",
    "    print(f\"{script} not found in repo root. Check that you've cloned the repo and are in the correct directory.\")\n",
    "else:\n",
    "    print(f\"Found {script} (size: {os.path.getsize(script)} bytes). Ready to run dry-run validation.\")\n",
    "# Optionally display first 200 lines for quick inspection\n",
    "try:\n",
    "    with open(script, 'r', encoding='utf-8') as fh:\n",
    "        print('--- top of script ---')\n",
    "        for i, line in enumerate(fh):\n",
    "            if i >= 200: break\n",
    "            print(line.rstrip())\n",
    "except Exception as e:\n",
    "    print('Could not open script file:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e9c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Dry-run validation (--dry-run)\n",
    "import os\n",
    "os.environ['DRY_RUN'] = '1'\n",
    "print('Starting dry-run validation: this will not download large datasets (DRY_RUN=1)')\n",
    "!python FarmFederate_Kaggle_Complete.py --dry-run 2>&1 | tee results/dry_run.log\n",
    "print('\\nLast 60 lines of dry-run log:')\n",
    "!tail -n 60 results/dry_run.log || true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afb4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Inspect dataset discovery & run status reports\n",
    "import json, os\n",
    "for fname in ['results/run_status.json','results/dataset_discovery_manifest.json','datasets_report.json','results/colab_full_run.log']:\n",
    "    if os.path.exists(fname):\n",
    "        print('\\n---', fname, '---')\n",
    "        try:\n",
    "            if fname.endswith('.json'):\n",
    "                print(json.dumps(json.load(open(fname, 'r')), indent=2)[:2000])\n",
    "            else:\n",
    "                print('\\n'.join(open(fname,'r').read().splitlines()[-50:]))\n",
    "        except Exception as e:\n",
    "            print('Could not pretty-print', fname, e)\n",
    "    else:\n",
    "        print(fname, 'not found yet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10b) AUTOMATED: Full ingestion (Qdrant) + full run (training/eval)\n",
    "# WARNING: This will download datasets, ingest into Qdrant, and run the full training pipeline.\n",
    "# Use with care in a Colab GPU runtime. You will be prompted for confirmation and limits.\n",
    "import os, sys, subprocess, getpass, time\n",
    "print('\\n=== AUTOMATED: Full ingestion + full run (with Qdrant) ===')\n",
    "confirm = input('Proceed with ingestion + full run now? This may take hours and consume substantial disk (y/N): ').strip().lower() or 'n'\n",
    "if confirm != 'y':\n",
    "    print('Aborted by user. No actions taken.')\n",
    "else:\n",
    "    # Qdrant mode selection\n",
    "    mode = input('Qdrant mode (inmemory / remote) [default: inmemory]: ').strip().lower() or 'inmemory'\n",
    "    if mode == 'remote':\n",
    "        qdrant_url = input('Enter QDRANT_URL (e.g., http://host:6333): ').strip()\n",
    "        qdrant_key = getpass.getpass('Enter QDRANT_API_KEY (leave blank if none): ').strip()\n",
    "        if qdrant_url:\n",
    "            os.environ['QDRANT_URL'] = qdrant_url\n",
    "        if qdrant_key:\n",
    "            os.environ['QDRANT_API_KEY'] = qdrant_key\n",
    "    else:\n",
    "        qdrant_url = ':memory:'\n",
    "\n",
    "    # Limits\n",
    "    try:\n",
    "        max_files = int(input('Max images per dataset to ingest [default: 200]: ').strip() or '200')\n",
    "    except Exception:\n",
    "        max_files = 200\n",
    "    try:\n",
    "        max_text = int(input('Max text records per HF dataset [default: 200]: ').strip() or '200')\n",
    "    except Exception:\n",
    "        max_text = 200\n",
    "    use_defaults = input('Use recommended default datasets? (Y/n) [default: Y]: ').strip().lower() or 'y'\n",
    "    use_defaults_flag = '--use-defaults' if use_defaults == 'y' else ''\n",
    "\n",
    "    # Ensure core packages available\n",
    "    print('\\nInstalling/checking core packages for RAG and ingestion (may be quiet)')\n",
    "    pkgs = ['qdrant-client','sentence-transformers','transformers','datasets','kaggle','huggingface_hub']\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q'] + pkgs)\n",
    "\n",
    "    # Run ingestion\n",
    "    ingest_cmd = [sys.executable, 'backend/ingest_real_datasets.py', '--qdrant-url', qdrant_url, '--max-files', str(max_files), '--max-text', str(max_text)]\n",
    "    if use_defaults_flag:\n",
    "        ingest_cmd.append(use_defaults_flag)\n",
    "    print('\\nRunning ingestion into Qdrant with:')\n",
    "    print(' '.join(ingest_cmd))\n",
    "    try:\n",
    "        start = time.time()\n",
    "        subprocess.run(ingest_cmd, check=True)\n",
    "        print(f'Ingestion completed in {(time.time()-start)/60:.1f} minutes')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print('Ingestion failed (non-zero exit). Check output above and logs in results/. Continuing to full run may fail.')\n",
    "\n",
    "    # Run full pipeline (training/eval)\n",
    "    os.environ['RUN_ON_COLAB'] = '1'\n",
    "    os.environ['DRY_RUN'] = '0'\n",
    "    print('\\nStarting full FarmFederate run (training/eval). Output will stream to results/colab_full_run.log')\n",
    "    full_cmd = [sys.executable, '-u', 'FarmFederate_Kaggle_Complete.py']\n",
    "    try:\n",
    "        with open('results/colab_full_run.log', 'ab') as fh:\n",
    "            proc = subprocess.Popen(full_cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "            # stream output to file and console\n",
    "            for line in proc.stdout:\n",
    "                fh.write(line)\n",
    "                sys.stdout.buffer.write(line)\n",
    "        proc.wait()\n",
    "        print('\\nFull run completed (or exited). Inspect results/colab_full_run.log for details.')\n",
    "    except Exception as e:\n",
    "        print('Full run failed to start or crashed:', e)\n",
    "\n",
    "    # Quick RAG sanity test (best-effort)\n",
    "    print('\\nRunning quick RAG sanity test (in-memory demo using current Qdrant).')\n",
    "    try:\n",
    "        from qdrant_client import QdrantClient\n",
    "        from backend.qdrant_rag import init_qdrant_collections, agentic_diagnose, Embedders\n",
    "        from PIL import Image\n",
    "        # If remote mode was requested, attempt to use provided URL; otherwise use in-memory client to test local retrieval\n",
    "        client = QdrantClient(qdrant_url) if qdrant_url != ':memory:' else QdrantClient(':memory:')\n",
    "        init_qdrant_collections(client, recreate=False)\n",
    "        emb = Embedders()\n",
    "        test_img = Image.new('RGB', (224,224), color='green')\n",
    "        res = agentic_diagnose(client, image=test_img, user_description='Yellow spots on maize leaf (smoke test)', emb=emb, llm_func=lambda prompt: 'Mock response for smoke test')\n",
    "        print('RAG smoke test retrieved entries:', len(res.get('retrieved', [])))\n",
    "    except Exception as e:\n",
    "        print('RAG smoke test skipped or failed (missing optional deps or remote Qdrant unreachable):', e)\n",
    "\n",
    "    # Offer Drive sync if mounted\n",
    "    try:\n",
    "        drive_root = '/content/drive/MyDrive/FarmFederate-results'\n",
    "        if os.path.exists(drive_root):\n",
    "            print('\\nSyncing results and checkpoints to Drive at', drive_root)\n",
    "            import shutil\n",
    "            shutil.copytree('results', os.path.join(drive_root, 'results'), dirs_exist_ok=True)\n",
    "            if os.path.exists('checkpoints'):\n",
    "                shutil.copytree('checkpoints', os.path.join(drive_root, 'checkpoints'), dirs_exist_ok=True)\n",
    "            print('Sync complete')\n",
    "        else:\n",
    "            print('\\nDrive sync skipped: Drive not mounted or path not found (run the Drive mount cell first).')\n",
    "    except Exception as e:\n",
    "        print('Drive sync failed:', e)\n",
    "\n",
    "    print('\\n=== ALL DONE (or stopped on error). Inspect logs & results/ for artifacts. ===')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10c) HEADLESS: Full ingestion + full run (non-interactive)\n",
    "# This cell runs ingestion into Qdrant (default :memory:) then runs the full pipeline (training/eval) and a quick RAG smoke test.\n",
    "# WARNING: Running this cell will start long-running downloads and training. Run only when you are ready and on a GPU runtime.\n",
    "import os, sys, subprocess, time\n",
    "print('\\n=== HEADLESS: Full ingestion + full run (non-interactive) ===')\n",
    "# Defaults (adjust here if you want different defaults)\n",
    "qdrant_url = os.environ.get('QDRANT_URL', ':memory:')\n",
    "max_files = int(os.environ.get('MAX_FILES_PER_DATASET', '200'))\n",
    "max_text = int(os.environ.get('MAX_TEXT_PER_HF', '200'))\n",
    "use_defaults = os.environ.get('USE_DEFAULTS', '1') in ('1','true','True')\n",
    "\n",
    "# Install required packages quietly\n",
    "pkgs = ['qdrant-client','sentence-transformers','transformers','datasets','kaggle','huggingface_hub']\n",
    "print('Ensuring packages are installed:', pkgs)\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q'] + pkgs)\n",
    "\n",
    "# Build ingestion command\n",
    "ingest_cmd = [sys.executable, 'backend/ingest_real_datasets.py', '--qdrant-url', qdrant_url, '--max-files', str(max_files), '--max-text', str(max_text)]\n",
    "if use_defaults:\n",
    "    ingest_cmd.append('--use-defaults')\n",
    "print('\\nRunning ingestion:')\n",
    "print(' '.join(ingest_cmd))\n",
    "try:\n",
    "    start = time.time()\n",
    "    subprocess.run(ingest_cmd, check=True)\n",
    "    print(f'Ingestion completed in {(time.time()-start)/60:.1f} minutes')\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print('Ingestion exited with non-zero status; check logs. Proceeding to full run cautiously.')\n",
    "\n",
    "# Run full pipeline (training/eval)\n",
    "print('\\nStarting full FarmFederate run (training/eval). This can take a long time.')\n",
    "os.environ['RUN_ON_COLAB'] = '1'\n",
    "os.environ['DRY_RUN'] = '0'\n",
    "full_cmd = [sys.executable, '-u', 'FarmFederate_Kaggle_Complete.py']\n",
    "print('Launching full run:',' '.join(full_cmd))\n",
    "try:\n",
    "    with open('results/colab_full_run.log', 'ab') as fh:\n",
    "        proc = subprocess.Popen(full_cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        for line in proc.stdout:\n",
    "            fh.write(line)\n",
    "            sys.stdout.buffer.write(line)\n",
    "    proc.wait()\n",
    "    print('\\nFull run completed (or exited). Inspect results/colab_full_run.log for details.')\n",
    "except Exception as e:\n",
    "    print('Full run failed to start or crashed:', e)\n",
    "\n",
    "# Quick RAG smoke test\n",
    "print('\\nQuick RAG smoke test (best-effort)')\n",
    "try:\n",
    "    from qdrant_client import QdrantClient\n",
    "    from backend.qdrant_rag import init_qdrant_collections, agentic_diagnose, Embedders\n",
    "    from PIL import Image\n",
    "    client = QdrantClient(qdrant_url) if qdrant_url != ':memory:' else QdrantClient(':memory:')\n",
    "    init_qdrant_collections(client, recreate=False)\n",
    "    emb = Embedders()\n",
    "    test_img = Image.new('RGB', (224,224), color='green')\n",
    "    res = agentic_diagnose(client, image=test_img, user_description='Yellow spots (smoke test)', emb=emb, llm_func=lambda prompt: 'Smoke test LLM')\n",
    "    print('RAG test retrieved entries:', len(res.get('retrieved', [])))\n",
    "except Exception as e:\n",
    "    print('RAG smoke test skipped/failed:', e)\n",
    "\n",
    "# Optional Drive sync (if mounted)\n",
    "try:\n",
    "    drive_root = '/content/drive/MyDrive/FarmFederate-results'\n",
    "    if os.path.exists(drive_root):\n",
    "        print('\\nSyncing results and checkpoints to Drive at', drive_root)\n",
    "        import shutil\n",
    "        shutil.copytree('results', os.path.join(drive_root, 'results'), dirs_exist_ok=True)\n",
    "        if os.path.exists('checkpoints'):\n",
    "            shutil.copytree('checkpoints', os.path.join(drive_root, 'checkpoints'), dirs_exist_ok=True)\n",
    "        print('Sync complete')\n",
    "    else:\n",
    "        print('\\nDrive not mounted; skipping sync')\n",
    "except Exception as e:\n",
    "    print('Drive sync failed:', e)\n",
    "\n",
    "print('\\n=== HEADLESS RUN FINISHED (or stopped on error). Check results/* for artifacts. ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c6ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-CLICK: AUTO START FULL RUN (interactive)\n",
    "# WARNING: This will perform ingestion and then the full training pipeline. Use with care (GPU runtime required).\n",
    "import os, sys, getpass, subprocess, time\n",
    "print('\\n=== ONE-CLICK AUTO START: Ingest + Full Run ===')\n",
    "confirm = input('Confirm start FULL RUN now? This may take hours and use large disk (y/N): ').strip().lower() or 'n'\n",
    "if confirm != 'y':\n",
    "    print('Aborted by user. No actions taken.')\n",
    "else:\n",
    "    # Upload kaggle.json if desired\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print('\\nUpload kaggle.json now (or cancel to use env vars)')\n",
    "        uploaded = files.upload()\n",
    "        if uploaded:\n",
    "            kaggle_dir = '/root/.kaggle'\n",
    "            os.makedirs(kaggle_dir, exist_ok=True)\n",
    "            for fn, data in uploaded.items():\n",
    "                open(os.path.join(kaggle_dir, 'kaggle.json'), 'wb').write(data)\n",
    "            try:\n",
    "                os.chmod(os.path.join(kaggle_dir, 'kaggle.json'), 0o600)\n",
    "            except Exception:\n",
    "                pass\n",
    "            print('Saved kaggle.json to ~/.kaggle/kaggle.json')\n",
    "    except Exception:\n",
    "        print('Upload not available; ensure KAGGLE_USERNAME/KAGGLE_KEY env vars if needed')\n",
    "\n",
    "    # Tokens\n",
    "    hf = getpass.getpass('Enter HF_TOKEN (leave blank to skip): ')\n",
    "    if hf:\n",
    "        os.environ['HF_TOKEN'] = hf\n",
    "    gh = getpass.getpass('Enter GITHUB_TOKEN (leave blank to skip): ')\n",
    "    if gh:\n",
    "        os.environ['GITHUB_TOKEN'] = gh\n",
    "\n",
    "    # Qdrant mode\n",
    "    mode = input('Qdrant mode (inmemory / remote) [default: inmemory]: ').strip().lower() or 'inmemory'\n",
    "    if mode == 'remote':\n",
    "        url = input('Enter QDRANT_URL (e.g., http://host:6333): ').strip()\n",
    "        key = getpass.getpass('Enter QDRANT_API_KEY (leave blank if none): ').strip()\n",
    "        if url:\n",
    "            os.environ['QDRANT_URL'] = url\n",
    "        if key:\n",
    "            os.environ['QDRANT_API_KEY'] = key\n",
    "    else:\n",
    "        os.environ['QDRANT_URL'] = ':memory:'\n",
    "\n",
    "    # Limits\n",
    "    max_files = input('Max images per dataset to ingest [200]: ').strip() or '200'\n",
    "    max_text = input('Max text records per HF dataset [200]: ').strip() or '200'\n",
    "    os.environ['MAX_FILES_PER_DATASET'] = str(max_files)\n",
    "    os.environ['MAX_TEXT_PER_HF'] = str(max_text)\n",
    "    os.environ['USE_DEFAULTS'] = '1'\n",
    "\n",
    "    # Environment flags\n",
    "    os.environ['RUN_ON_COLAB'] = '1'\n",
    "    os.environ['DRY_RUN'] = '0'\n",
    "\n",
    "    # Install required packages\n",
    "    print('\\nInstalling required RAG/ingest packages (quiet)')\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'qdrant-client', 'sentence-transformers', 'transformers', 'datasets', 'kaggle', 'huggingface_hub'])\n",
    "\n",
    "    # Run ingestion\n",
    "    ingest_cmd = [sys.executable, 'backend/ingest_real_datasets.py', '--qdrant-url', os.environ.get('QDRANT_URL', ':memory:'), '--max-files', os.environ['MAX_FILES_PER_DATASET'], '--max-text', os.environ['MAX_TEXT_PER_HF'], '--use-defaults']\n",
    "    print('\\nRunning ingestion:')\n",
    "    print(' '.join(ingest_cmd))\n",
    "    try:\n",
    "        start = time.time()\n",
    "        subprocess.run(ingest_cmd, check=True)\n",
    "        print(f'Ingestion finished in {(time.time()-start)/60:.1f} minutes')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print('Ingestion failed (non-zero exit). Check logs and results/ for details. Continuing to full run may fail.')\n",
    "\n",
    "    # Run full pipeline\n",
    "    print('\\nStarting full FarmFederate run (training/eval). Output will stream to results/colab_full_run.log')\n",
    "    full_cmd = [sys.executable, '-u', 'FarmFederate_Kaggle_Complete.py']\n",
    "    try:\n",
    "        subprocess.run(full_cmd, check=True)\n",
    "        print('Full run completed (or exited). Inspect results/colab_full_run.log and results/* for artifacts.')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print('Full run failed (non-zero exit). Check results/colab_full_run.log for details:', e)\n",
    "\n",
    "    # Quick RAG smoke test\n",
    "    print('\\nAttempting quick RAG smoke test...')\n",
    "    try:\n",
    "        from qdrant_client import QdrantClient\n",
    "        from backend.qdrant_rag import init_qdrant_collections, agentic_diagnose, Embedders\n",
    "        from PIL import Image\n",
    "        client = QdrantClient(os.environ.get('QDRANT_URL', ':memory:')) if os.environ.get('QDRANT_URL') != ':memory:' else QdrantClient(':memory:')\n",
    "        init_qdrant_collections(client, recreate=False)\n",
    "        emb = Embedders()\n",
    "        test_img = Image.new('RGB', (224,224), color='green')\n",
    "        res = agentic_diagnose(client, image=test_img, user_description='Smoke test', emb=emb, llm_func=lambda prompt: 'Smoke LLM')\n",
    "        print('RAG smoke test retrieved entries:', len(res.get('retrieved', [])))\n",
    "    except Exception as e:\n",
    "        print('RAG smoke test skipped/failed:', e)\n",
    "\n",
    "    print('\\n=== AUTO START FULL RUN FINISHED (or stopped on error). Check results/* for artifacts. ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a965526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Enable full run & start script (WARNING: long-running)\n",
    "import os\n",
    "os.environ['RUN_ON_COLAB'] = '1'\n",
    "os.environ['DRY_RUN'] = '0'\n",
    "os.environ['CLONE_GITHUB_REPOS'] = '1'\n",
    "print('Starting full run. Output is streamed to results/colab_full_run.log')\n",
    "!python -u FarmFederate_Kaggle_Complete.py 2>&1 | tee results/colab_full_run.log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe86b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Tail logs (run in a separate cell to monitor progress)\n",
    "print('Tail the last 200 lines of the live log')\n",
    "!tail -n 200 results/colab_full_run.log || true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Sync results & checkpoints to Drive (if mounted)\n",
    "try:\n",
    "    import shutil, os\n",
    "    drive_root = '/content/drive/MyDrive/FarmFederate-results'\n",
    "    if os.path.exists(drive_root):\n",
    "        print('Copying results/ ->', drive_root)\n",
    "        shutil.copytree('results', os.path.join(drive_root, 'results'), dirs_exist_ok=True)\n",
    "        if os.path.exists('checkpoints'):\n",
    "            shutil.copytree('checkpoints', os.path.join(drive_root, 'checkpoints'), dirs_exist_ok=True)\n",
    "        print('Sync complete')\n",
    "    else:\n",
    "        print('Drive path not present. Make sure you mounted Drive and created the folder at', drive_root)\n",
    "except Exception as e:\n",
    "    print('Sync failed:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0976be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) Quick RAG / Qdrant test snippet (optional)\n",
    "try:\n",
    "    from qdrant_client import QdrantClient\n",
    "    from backend.qdrant_rag import init_qdrant_collections, agentic_diagnose, Embedders\n",
    "    from PIL import Image\n",
    "    print('Initializing in-memory Qdrant...')\n",
    "    client = QdrantClient(':memory:')\n",
    "    init_qdrant_collections(client, recreate=True)\n",
    "    emb = Embedders()\n",
    "    # Simple empty search demo\n",
    "    test_img = Image.new('RGB', (224,224), color='green')\n",
    "    res = agentic_diagnose(client, image=test_img, user_description='Yellow spots on maize leaf', emb=emb, llm_func=lambda prompt: 'Mock LLM response: advice')\n",
    "    print('Retrieved:', len(res.get('retrieved', [])))\n",
    "    print('Prompt preview:')\n",
    "    print(res['prompt'][:800])\n",
    "except Exception as e:\n",
    "    print('RAG test skipped or failed (missing optional deps):', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13b) DEMO: FarmMemoryAgent store + retrieve demo\n",
    "# Stores a few sample reports into an in-memory Qdrant collection and retrieves the top-3 visually similar events for the demo farm.\n",
    "try:\n",
    "    from backend.farm_memory_agent import FarmMemoryAgent\n",
    "    import numpy as np\n",
    "    import pprint\n",
    "\n",
    "    print('Initializing demo FarmMemoryAgent (in-memory Qdrant)')\n",
    "    agent = FarmMemoryAgent(qdrant_url=':memory:')\n",
    "    agent.init_collection(recreate=True)\n",
    "\n",
    "    # Create three sample reports for farm 'demo-farm-1'\n",
    "    emb_base = np.random.RandomState(42).randn(agent._visual_dim)\n",
    "    ids = []\n",
    "    ids.append(agent.store_report('Severe water stress - leaves drooping', emb_base.tolist(), np.random.rand(agent._semantic_dim).tolist(), farm_id='demo-farm-1', metadata={'severity':'severe'}))\n",
    "    ids.append(agent.store_report('Early signs of nutrient deficiency - yellowing', (emb_base*0.9).tolist(), np.random.rand(agent._semantic_dim).tolist(), farm_id='demo-farm-1', metadata={'severity':'medium'}))\n",
    "    ids.append(agent.store_report('Possible pest risk - small holes on leaves', (emb_base*1.1).tolist(), np.random.rand(agent._semantic_dim).tolist(), farm_id='demo-farm-1', metadata={'severity':'low'}))\n",
    "\n",
    "    # One report for another farm\n",
    "    agent.store_report('Heat stress observed', np.random.RandomState(1).randn(agent._visual_dim).tolist(), np.random.rand(agent._semantic_dim).tolist(), farm_id='demo-farm-2')\n",
    "\n",
    "    print('\\nStored sample reports with ids:', ids)\n",
    "\n",
    "    # Query using the base embedding; expect the three demo-farm-1 reports to be the top hits\n",
    "    print('\\nRetrieving top-3 visually similar reports for demo-farm-1')\n",
    "    hits = agent.retrieve_similar_by_image(emb_base.tolist(), farm_id='demo-farm-1', top_k=3)\n",
    "    pprint.pprint(hits)\n",
    "\n",
    "    # Export CSV and show first lines\n",
    "    out_csv = agent.export_reports_to_csv('demo-farm-1', out_path='results/demo_farm_1_history.csv')\n",
    "    print('\\nExported CSV to', out_csv)\n",
    "    try:\n",
    "        with open(out_csv,'r',encoding='utf-8') as fh:\n",
    "            for i, line in enumerate(fh):\n",
    "                print(line.rstrip())\n",
    "                if i >= 5:\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print('Could not read CSV:', e)\n",
    "\n",
    "    print('\\nFarmMemoryAgent demo completed successfully')\n",
    "except Exception as e:\n",
    "    print('FarmMemoryAgent demo failed:', e)\n",
    "    print('If running locally, ensure qdrant-client is installed; in Colab run the setup cell first to install packages.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) Visualize saved plots & read reports\n",
    "import os\n",
    "from IPython.display import display, Image as IPyImage\n",
    "print('Plots directory listing:')\n",
    "for f in sorted(os.listdir('plots') if os.path.exists('plots') else [] )[:50]:\n",
    "    print(' -', f)\n",
    "# Display a sample plot if present\n",
    "sample = None\n",
    "if os.path.exists('plots'):\n",
    "    files = [os.path.join('plots', f) for f in os.listdir('plots') if f.lower().endswith(('.png','.jpg'))]\n",
    "    if files:\n",
    "        sample = files[0]\n",
    "if sample:\n",
    "    print('Displaying sample plot:', sample)\n",
    "    display(IPyImage(sample))\n",
    "else:\n",
    "    print('No plot images found yet (run full experiment to generate plots)')\n",
    "\n",
    "# Print brief JSON summaries\n",
    "for fname in ['results/complete_results.json','results/epoch_sweep_results.json']:\n",
    "    if os.path.exists(fname):\n",
    "        import json\n",
    "        print('\\n---', fname, '---')\n",
    "        try:\n",
    "            d = json.load(open(fname,'r'))\n",
    "            print('Keys:', list(d.keys())[:20])\n",
    "        except Exception as e:\n",
    "            print('Error reading', fname, e)\n",
    "    else:\n",
    "        print(fname, 'not found yet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d439edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15) Compress final artifacts and offer for download (optional)\n",
    "!zip -r -q farmfederate_results.zip results plots checkpoints || true\n",
    "print('Created farmfederate_results.zip (if any artifacts present).')\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('farmfederate_results.zip')\n",
    "except Exception:\n",
    "    print('files.download not available; copy the zip from the notebook workspace or sync to Drive')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
