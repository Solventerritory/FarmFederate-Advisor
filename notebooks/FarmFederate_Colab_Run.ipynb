{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9769baf6",
   "metadata": {},
   "source": [
    "# Quick Start ‚Äî Run FarmFederate on Colab üöÄ\n",
    "\n",
    "Follow these steps in order (copy the provided cells into Colab):\n",
    "\n",
    "1. **Pre-setup**: Run the *pre-setup* cell to install missing packages and optionally upload `kaggle.json`. This sets safe defaults (DRY_RUN=1).\n",
    "2. **Dry-run**: The pre-setup cell will run a dry-run of `FarmFederate_Kaggle_Complete.py` to validate config and write manifests (`results/dataset_discovery_manifest.json`, `datasets_report.json`). Inspect these files.\n",
    "3. **Review & Accept**: If using Kaggle competitions (e.g., Plant Pathology), accept the terms on Kaggle and ensure `kaggle.json`/env vars are set. Set `HF_TOKEN` when prompted if you need HF datasets.\n",
    "4. **Full Run**: If dry-run looks good, proceed with the full run when prompted by the cell (it will set DRY_RUN=0). You can opt to clone GitHub fallback repos (CLONE_GITHUB_REPOS=1).\n",
    "5. **Drive Sync (optional)**: When you mount Drive, the one-click cell can copy `results/` and `checkpoints/` to your Drive folder for persistence.\n",
    "6. **Inspect Outputs**: After the run check `results/` (JSONs, metrics, plots) and `plots/` for images. Use `results/dataset_discovery_manifest.json` to review dataset acquisition details.\n",
    "\n",
    "Notes: Start with the dry-run to avoid long downloads by accident. If you want, run the **One-click** cell to perform the whole workflow interactively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb199f3",
   "metadata": {},
   "source": [
    "# FarmFederate: Colab Runbook\n",
    "\n",
    "This notebook prepares a Google Colab environment and runs the project script safely. Follow the cells in order and set the required credentials (Kaggle and HuggingFace) before enabling full downloads and training. The notebook is structured with safety guards so it will not perform heavy downloads unless you set RUN_ON_COLAB=1.\n",
    "\n",
    "*Outline:* Colab setup ‚Üí Install dependencies ‚Üí Credentials upload ‚Üí Flags & guards ‚Üí Run discovery/downloads (download-only or full) ‚Üí Training / Federated runs (fast-mode) ‚Üí Plots and export.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4122c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Colab & Environment Setup\n",
    "\n",
    "# Mount Google Drive (optional) and check GPU runtime\n",
    "from google.colab import drive\n",
    "print('Mounting Google Drive... (optional)')\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "print('Device:', torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "\n",
    "# Safety: enable heavy runs explicitly\n",
    "import os\n",
    "print('IN_COLAB detected. To enable downloads and heavy runs set environment variable RUN_ON_COLAB=1')\n",
    "print('Example: %env RUN_ON_COLAB 1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Install Dependencies (run this cell)\n",
    "# Installs commonly required packages. Runs quietly in Colab.\n",
    "!pip install -q transformers datasets peft torch torchvision scikit-learn kaggle imgaug\n",
    "\n",
    "print('Installed core dependencies.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3688136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Notebook Flags & Runtime Guards\n",
    "import os\n",
    "# Example toggles\n",
    "os.environ.setdefault('RUN_ON_COLAB', '0')  # Set to '1' to allow heavy ops\n",
    "os.environ.setdefault('DRY_RUN', '1')       # Set to '0' to enable full downloads\n",
    "os.environ.setdefault('DOWNLOAD_ONLY', '0')\n",
    "os.environ.setdefault('REPORT_ONLY', '0')\n",
    "\n",
    "print('RUN_ON_COLAB=', os.environ['RUN_ON_COLAB'])\n",
    "print('DRY_RUN=', os.environ['DRY_RUN'])\n",
    "print('DOWNLOAD_ONLY=', os.environ['DOWNLOAD_ONLY'])\n",
    "print('REPORT_ONLY=', os.environ['REPORT_ONLY'])\n",
    "\n",
    "print('\\nTo enable full Colab run, execute:')\n",
    "print('%env RUN_ON_COLAB 1')\n",
    "print('%env DRY_RUN 0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Kaggle & HuggingFace Credentials\n",
    "from google.colab import files\n",
    "import os\n",
    "print('Upload kaggle.json (optional) or set KAGGLE_USERNAME and KAGGLE_KEY as environment variables')\n",
    "print('If you have kaggle.json file, use the upload widget:')\n",
    "\n",
    "uploaded = files.upload()\n",
    "if uploaded:\n",
    "    kaggle_dir = '/root/.kaggle'\n",
    "    os.makedirs(kaggle_dir, exist_ok=True)\n",
    "    for fn in uploaded.keys():\n",
    "        dest = os.path.join(kaggle_dir, 'kaggle.json')\n",
    "        open(dest, 'wb').write(uploaded[fn])\n",
    "        try:\n",
    "            os.chmod(dest, 0o600)\n",
    "        except Exception:\n",
    "            pass\n",
    "    print('Saved uploaded kaggle.json to ~/.kaggle/kaggle.json')\n",
    "\n",
    "print('\\nTo set HF_TOKEN securely, run:')\n",
    "print('%env HF_TOKEN your_hf_token_here')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b6bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Quick validation & small DRY_RUN test (safe)\n",
    "# This will run the script in dry-run mode to validate flags and manifest writing without downloads.\n",
    "import os\n",
    "os.environ['DRY_RUN'] = os.environ.get('DRY_RUN', '1')\n",
    "print('Running a quick dry-run of dataset discovery (DRY_RUN=1) to validate configuration...')\n",
    "!python FarmFederate_Kaggle_Complete.py --dry-run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6794dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Full run (enable when ready)\n",
    "# Set RUN_ON_COLAB=1 and toggle other flags as needed before running this cell.\n",
    "import os\n",
    "os.environ['RUN_ON_COLAB'] = '1'  # enable downloads / cloning\n",
    "os.environ['DRY_RUN'] = '0'       # disable dry-run to allow downloads\n",
    "# Default to cloning fallback sources\n",
    "os.environ['CLONE_GITHUB_REPOS'] = '1'\n",
    "print('RUN_ON_COLAB, DRY_RUN, CLONE_GITHUB_REPOS set to:', os.environ['RUN_ON_COLAB'], os.environ['DRY_RUN'], os.environ['CLONE_GITHUB_REPOS'])\n",
    "\n",
    "# Run the main script (this performs discovery, optional downloads, dataset building)\n",
    "# It may take a long time depending on datasets and whether you allow Kaggle/HTTP downloads.\n",
    "!python FarmFederate_Kaggle_Complete.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a26e636",
   "metadata": {},
   "source": [
    "# Notes & Checklist\n",
    "\n",
    "- ‚òëÔ∏è Upload `kaggle.json` or set `KAGGLE_USERNAME` and `KAGGLE_KEY` via `%env`.\n",
    "- ‚òëÔ∏è Set `HF_TOKEN` via `%env HF_TOKEN <token>` for HuggingFace access if needed.\n",
    "- ‚ö†Ô∏è Make sure you accept Kaggle competition terms for `plant-pathology-2020-fgvc7` if using that dataset.\n",
    "- üîß If anything fails, start with the quick DRY_RUN cell and inspect `results/dataset_discovery_manifest.json` and `datasets_report.json`.\n",
    "\n",
    "If you'd like, I can: (a) push this notebook to the repo and (b) prepare a short Colab-specific README cell with step-by-step commands for one-click runs. Which would you prefer next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8668f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-click: Full setup + run (copy & paste into Colab)\n",
    "\n",
    "# This single cell installs missing packages, mounts Drive (optional), uploads credentials,\n",
    "# runs a DRY-RUN to validate, then optionally proceeds to the full run and syncs results to Drive.\n",
    "\n",
    "import importlib, subprocess, sys, os, getpass\n",
    "from google.colab import drive, files\n",
    "\n",
    "# Install missing packages\n",
    "packages = ['transformers','datasets','peft','torch','torchvision','scikit-learn','kaggle','imgaug']\n",
    "toinstall = []\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        importlib.import_module(pkg if pkg != 'scikit-learn' else 'sklearn')\n",
    "    except Exception:\n",
    "        toinstall.append(pkg)\n",
    "if toinstall:\n",
    "    print('Installing:', toinstall)\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q'] + toinstall)\n",
    "else:\n",
    "    print('All required packages appear to be installed.')\n",
    "\n",
    "# Optional: mount Drive\n",
    "use_drive = input('Mount Google Drive to save results? (y/N): ').strip().lower() == 'y'\n",
    "drive_path = None\n",
    "if use_drive:\n",
    "    drive.mount('/content/drive')\n",
    "    drive_path = input('Enter Drive folder path to save results (e.g., /content/drive/MyDrive/FarmFederate-results) or leave blank to use default: ').strip()\n",
    "    if not drive_path:\n",
    "        drive_path = '/content/drive/MyDrive/FarmFederate-results'\n",
    "\n",
    "# Upload kaggle.json optionally\n",
    "print('\\nUpload kaggle.json now (or press cancel to set KAGGLE_USERNAME/KAGGLE_KEY env vars manually)')\n",
    "uploaded = files.upload()\n",
    "if uploaded:\n",
    "    kaggle_dir = '/root/.kaggle'\n",
    "    os.makedirs(kaggle_dir, exist_ok=True)\n",
    "    for fn, data in uploaded.items():\n",
    "        open(os.path.join(kaggle_dir, 'kaggle.json'), 'wb').write(data)\n",
    "    try:\n",
    "        os.chmod(os.path.join(kaggle_dir, 'kaggle.json'), 0o600)\n",
    "    except Exception:\n",
    "        pass\n",
    "    print('Saved kaggle.json to ~/.kaggle/kaggle.json')\n",
    "\n",
    "# Set flags and HF_TOKEN\n",
    "os.environ['RUN_ON_COLAB'] = '1'\n",
    "os.environ['DRY_RUN'] = '1'  # start with dry-run\n",
    "os.environ['CLONE_GITHUB_REPOS'] = '1'  # default to cloning fallback repos during discovery\n",
    "hf = getpass.getpass('Enter HF_TOKEN (leave blank to skip): ')\n",
    "if hf:\n",
    "    os.environ['HF_TOKEN'] = hf\n",
    "\n",
    "print('\\nRunning DRY-RUN validation (this will not download data) ...')\n",
    "!python FarmFederate_Kaggle_Complete.py --dry-run\n",
    "\n",
    "# Prompt for full run\n",
    "resp = input('\\nDRY-RUN complete. Proceed to full run and allow downloads/clones? (y/N): ').strip().lower()\n",
    "if resp == 'y':\n",
    "    clone_resp = input('Enable cloning of GitHub fallback repos during discovery? (y/N): ').strip().lower()\n",
    "    if clone_resp != 'y':\n",
    "        os.environ['CLONE_GITHUB_REPOS'] = '0'\n",
    "    os.environ['DRY_RUN'] = '0'\n",
    "    print('\\nStarting full run (this may take a long time). Logs will appear below...')\n",
    "    !python FarmFederate_Kaggle_Complete.py\n",
    "    # Optionally copy results to Drive\n",
    "    if drive_path:\n",
    "        try:\n",
    "            import shutil\n",
    "            os.makedirs(drive_path, exist_ok=True)\n",
    "            print('Copying results/ and checkpoints/ to', drive_path)\n",
    "            shutil.copytree('results', os.path.join(drive_path, 'results'), dirs_exist_ok=True)\n",
    "            if os.path.exists('checkpoints'):\n",
    "                shutil.copytree('checkpoints', os.path.join(drive_path, 'checkpoints'), dirs_exist_ok=True)\n",
    "            print('Copied artifacts to Drive.')\n",
    "        except Exception as e:\n",
    "            print('Failed to copy to Drive:', e)\n",
    "else:\n",
    "    print('Exiting. Re-run the full run when you are ready (set DRY_RUN=0 to run fully).')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
