{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FarmFederate - Crop Stress Detection with Federated Learning\n",
    "\n",
    "This notebook trains multimodal models (LLM, ViT, VLM) for crop stress detection:\n",
    "- **Water Stress** - Drought, wilting, dry soil conditions\n",
    "- **Nutrient Deficiency** - Nitrogen, phosphorus, potassium deficiency\n",
    "- **Pest Risk** - Insect damage, mites, aphids\n",
    "- **Disease Risk** - Fungal, bacterial, viral infections\n",
    "- **Heat Stress** - Scorching, thermal damage\n",
    "\n",
    "## Features\n",
    "- Real datasets from HuggingFace and Kaggle\n",
    "- Federated learning with differential privacy\n",
    "- Multiple model architectures\n",
    "- Qdrant vector database for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision transformers datasets\n",
    "!pip install -q pillow pandas numpy scikit-learn tqdm\n",
    "!pip install -q qdrant-client sentence-transformers\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Data\n",
    "    max_samples_per_class: int = 500\n",
    "    image_size: int = 224\n",
    "    max_seq_length: int = 128\n",
    "    \n",
    "    # Model\n",
    "    num_labels: int = 5\n",
    "    \n",
    "    # Training\n",
    "    batch_size: int = 16\n",
    "    epochs: int = 5\n",
    "    learning_rate: float = 2e-5\n",
    "    \n",
    "    # Federated\n",
    "    num_clients: int = 3\n",
    "    fed_rounds: int = 3\n",
    "    local_epochs: int = 2\n",
    "    \n",
    "    seed: int = 42\n",
    "\n",
    "config = Config()\n",
    "STRESS_LABELS = ['water_stress', 'nutrient_def', 'pest_risk', 'disease_risk', 'heat_stress']\n",
    "LABEL_TO_IDX = {label: idx for idx, label in enumerate(STRESS_LABELS)}\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"Labels: {STRESS_LABELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Real Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "# Disease to stress mapping\n",
    "def map_label_to_stress(label_name: str) -> Optional[str]:\n",
    "    label_lower = label_name.lower().replace(' ', '_').replace('-', '_')\n",
    "    \n",
    "    if any(kw in label_lower for kw in ['wilt', 'drought', 'dry', 'blight', 'spot']):\n",
    "        return 'water_stress'\n",
    "    if any(kw in label_lower for kw in ['yellow', 'pale', 'defic', 'chlorosis', 'mosaic']):\n",
    "        return 'nutrient_def'\n",
    "    if any(kw in label_lower for kw in ['mite', 'bug', 'insect', 'pest', 'aphid', 'miner']):\n",
    "        return 'pest_risk'\n",
    "    if any(kw in label_lower for kw in ['mold', 'mildew', 'rust', 'rot', 'fungus', 'bacteria', 'virus']):\n",
    "        return 'disease_risk'\n",
    "    if any(kw in label_lower for kw in ['scorch', 'burn', 'heat', 'sun']):\n",
    "        return 'heat_stress'\n",
    "    if 'healthy' not in label_lower:\n",
    "        return 'disease_risk'  # Default for unknown diseases\n",
    "    return None\n",
    "\n",
    "def load_hf_image_dataset(dataset_name: str, split: str, max_samples: int = 500) -> List[Dict]:\n",
    "    print(f\"  Loading {dataset_name}...\")\n",
    "    samples = []\n",
    "    try:\n",
    "        ds = load_dataset(dataset_name, split=split, streaming=True, trust_remote_code=True)\n",
    "        for i, item in enumerate(ds):\n",
    "            if i >= max_samples:\n",
    "                break\n",
    "            img = item.get('image') or item.get('img')\n",
    "            label_str = str(item.get('label', item.get('labels', item.get('disease', item.get('class', '')))))\n",
    "            if img is None:\n",
    "                continue\n",
    "            stress_label = map_label_to_stress(label_str)\n",
    "            if stress_label is None:\n",
    "                continue\n",
    "            if hasattr(img, 'convert'):\n",
    "                img = img.convert('RGB')\n",
    "            samples.append({\n",
    "                'image': img,\n",
    "                'label': LABEL_TO_IDX[stress_label],\n",
    "                'label_name': stress_label,\n",
    "                'source': dataset_name\n",
    "            })\n",
    "        print(f\"    Loaded {len(samples)} samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Failed: {e}\")\n",
    "    return samples\n",
    "\n",
    "def load_hf_text_dataset(dataset_name: str, max_samples: int = 500) -> List[Dict]:\n",
    "    print(f\"  Loading {dataset_name}...\")\n",
    "    samples = []\n",
    "    try:\n",
    "        ds = load_dataset(dataset_name, streaming=True, trust_remote_code=True)\n",
    "        if hasattr(ds, 'keys'):\n",
    "            split_name = list(ds.keys())[0]\n",
    "            ds = ds[split_name]\n",
    "        for i, item in enumerate(ds):\n",
    "            if i >= max_samples:\n",
    "                break\n",
    "            text = None\n",
    "            for key in ['text', 'content', 'description', 'abstract', 'title']:\n",
    "                if key in item and item[key]:\n",
    "                    text = str(item[key])\n",
    "                    break\n",
    "            if text is None or len(text) < 50:\n",
    "                continue\n",
    "            text_lower = text.lower()\n",
    "            stress_label = None\n",
    "            if any(kw in text_lower for kw in ['drought', 'water stress', 'irrigation', 'wilting']):\n",
    "                stress_label = 'water_stress'\n",
    "            elif any(kw in text_lower for kw in ['nutrient', 'nitrogen', 'phosphorus', 'potassium', 'fertilizer']):\n",
    "                stress_label = 'nutrient_def'\n",
    "            elif any(kw in text_lower for kw in ['pest', 'insect', 'aphid', 'mite', 'beetle']):\n",
    "                stress_label = 'pest_risk'\n",
    "            elif any(kw in text_lower for kw in ['disease', 'fungus', 'bacteria', 'virus', 'pathogen']):\n",
    "                stress_label = 'disease_risk'\n",
    "            elif any(kw in text_lower for kw in ['heat', 'temperature', 'thermal', 'climate']):\n",
    "                stress_label = 'heat_stress'\n",
    "            else:\n",
    "                stress_label = STRESS_LABELS[i % len(STRESS_LABELS)]\n",
    "            samples.append({\n",
    "                'text': text[:512],\n",
    "                'label': LABEL_TO_IDX[stress_label],\n",
    "                'label_name': stress_label,\n",
    "                'source': dataset_name\n",
    "            })\n",
    "        print(f\"    Loaded {len(samples)} samples\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Failed: {e}\")\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic data generation for missing classes\n",
    "def generate_synthetic_samples(n_per_class: int = 100):\n",
    "    TEXT_TEMPLATES = {\n",
    "        'water_stress': [\n",
    "            \"The crop shows signs of water stress with wilting leaves and dry soil conditions.\",\n",
    "            \"Drought conditions have caused leaf curling and reduced plant turgor.\",\n",
    "            \"Insufficient irrigation has led to yellowing of lower leaves and stunted growth.\",\n",
    "        ],\n",
    "        'nutrient_def': [\n",
    "            \"Nitrogen deficiency is evident from the pale green to yellow coloration of older leaves.\",\n",
    "            \"Phosphorus deficiency shows as purple discoloration on leaf undersides.\",\n",
    "            \"Potassium deficiency manifests as brown scorching on leaf edges.\",\n",
    "        ],\n",
    "        'pest_risk': [\n",
    "            \"Spider mite infestation visible as stippling and webbing on leaf surfaces.\",\n",
    "            \"Aphid colony detected on new growth causing leaf curl and honeydew deposits.\",\n",
    "            \"Leaf miner damage appears as serpentine trails within leaf tissue.\",\n",
    "        ],\n",
    "        'disease_risk': [\n",
    "            \"Powdery mildew infection presents as white fungal growth on leaf surfaces.\",\n",
    "            \"Bacterial leaf spot causes water-soaked lesions with yellow halos.\",\n",
    "            \"Fungal rust disease shows as orange pustules on leaf undersides.\",\n",
    "        ],\n",
    "        'heat_stress': [\n",
    "            \"Heat stress has caused leaf scorching and premature senescence.\",\n",
    "            \"High temperature damage visible as bleached areas on sun-exposed leaves.\",\n",
    "            \"Thermal injury shows as brown necrotic patches on leaf tissue.\",\n",
    "        ]\n",
    "    }\n",
    "    CLASS_COLORS = {\n",
    "        'water_stress': (80, 120, 60),\n",
    "        'nutrient_def': (180, 180, 80),\n",
    "        'pest_risk': (100, 130, 80),\n",
    "        'disease_risk': (120, 100, 70),\n",
    "        'heat_stress': (150, 130, 90),\n",
    "    }\n",
    "    text_samples, image_samples = [], []\n",
    "    for label_name, label_idx in LABEL_TO_IDX.items():\n",
    "        templates = TEXT_TEMPLATES[label_name]\n",
    "        base_color = CLASS_COLORS[label_name]\n",
    "        for i in range(n_per_class):\n",
    "            text_samples.append({\n",
    "                'text': templates[i % len(templates)] + f\" Observed in field plot {i+1}.\",\n",
    "                'label': label_idx,\n",
    "                'label_name': label_name,\n",
    "                'source': 'synthetic'\n",
    "            })\n",
    "            img_array = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "            r, g, b = base_color\n",
    "            noise = np.random.randint(-30, 30, (224, 224, 3))\n",
    "            img_array[:, :, 0] = np.clip(r + noise[:, :, 0], 0, 255)\n",
    "            img_array[:, :, 1] = np.clip(g + noise[:, :, 1], 0, 255)\n",
    "            img_array[:, :, 2] = np.clip(b + noise[:, :, 2], 0, 255)\n",
    "            # Add class-specific patterns\n",
    "            if label_name == 'pest_risk':\n",
    "                for _ in range(np.random.randint(15, 30)):\n",
    "                    cx, cy = np.random.randint(10, 214, 2)\n",
    "                    radius = np.random.randint(2, 6)\n",
    "                    y, x = np.ogrid[:224, :224]\n",
    "                    mask = ((x - cx)**2 + (y - cy)**2) < radius**2\n",
    "                    img_array[mask] = (img_array[mask] * 0.2).astype(np.uint8)\n",
    "            elif label_name == 'disease_risk':\n",
    "                for _ in range(np.random.randint(2, 5)):\n",
    "                    cx, cy = np.random.randint(30, 194, 2)\n",
    "                    radius = np.random.randint(15, 40)\n",
    "                    y, x = np.ogrid[:224, :224]\n",
    "                    mask = ((x - cx)**2 + (y - cy)**2) < radius**2\n",
    "                    img_array[mask, 0] = np.clip(100 + np.random.randint(-15, 15), 0, 255)\n",
    "                    img_array[mask, 1] = np.clip(70 + np.random.randint(-15, 15), 0, 255)\n",
    "                    img_array[mask, 2] = np.clip(40 + np.random.randint(-15, 15), 0, 255)\n",
    "            img = Image.fromarray(img_array, mode='RGB')\n",
    "            image_samples.append({\n",
    "                'image': img,\n",
    "                'label': label_idx,\n",
    "                'label_name': label_name,\n",
    "                'source': 'synthetic'\n",
    "            })\n",
    "    return text_samples, image_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "print(\"=\" * 70)\n",
    "print(\"LOADING DATASETS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_text_samples = []\n",
    "all_image_samples = []\n",
    "\n",
    "# HuggingFace image datasets\n",
    "HF_IMAGE_DATASETS = [\n",
    "    (\"BrandonFors/Plant-Diseases-PlantVillage-Dataset\", \"train\"),\n",
    "    (\"agyaatcoder/PlantDoc\", \"train\"),\n",
    "]\n",
    "\n",
    "print(\"\\n[Image Datasets]\")\n",
    "for dataset_name, split in HF_IMAGE_DATASETS:\n",
    "    samples = load_hf_image_dataset(dataset_name, split, max_samples=config.max_samples_per_class)\n",
    "    all_image_samples.extend(samples)\n",
    "\n",
    "# HuggingFace text datasets\n",
    "HF_TEXT_DATASETS = [\n",
    "    \"CGIAR/gardian-ai-ready-docs\",\n",
    "]\n",
    "\n",
    "print(\"\\n[Text Datasets]\")\n",
    "for dataset_name in HF_TEXT_DATASETS:\n",
    "    samples = load_hf_text_dataset(dataset_name, max_samples=config.max_samples_per_class)\n",
    "    all_text_samples.extend(samples)\n",
    "\n",
    "# Generate synthetic data to ensure coverage\n",
    "print(\"\\n[Generating Synthetic Data]\")\n",
    "syn_text, syn_images = generate_synthetic_samples(n_per_class=100)\n",
    "all_text_samples.extend(syn_text)\n",
    "all_image_samples.extend(syn_images)\n",
    "\n",
    "# Convert to DataFrames\n",
    "text_df = pd.DataFrame(all_text_samples)\n",
    "image_df = pd.DataFrame(all_image_samples)\n",
    "\n",
    "print(f\"\\n[Final Dataset Sizes]\")\n",
    "print(f\"  Text: {len(text_df)} samples\")\n",
    "print(f\"  Images: {len(image_df)} samples\")\n",
    "\n",
    "# Show class distribution\n",
    "print(\"\\n[Class Distribution]\")\n",
    "for label_name in STRESS_LABELS:\n",
    "    text_count = len(text_df[text_df['label_name'] == label_name])\n",
    "    image_count = len(image_df[image_df['label_name'] == label_name])\n",
    "    print(f\"  {label_name}: {text_count} text, {image_count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create PyTorch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AutoImageProcessor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Load tokenizer and image processor\n",
    "print(\"Loading tokenizer and image processor...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "image_processor = AutoImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=128):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            str(row['text']),\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        labels = torch.zeros(len(STRESS_LABELS), dtype=torch.float32)\n",
    "        labels[int(row['label'])] = 1.0\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, image_processor):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_processor = image_processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = row['image']\n",
    "        if not hasattr(img, 'convert'):\n",
    "            img = Image.fromarray(np.array(img))\n",
    "        img = img.convert('RGB')\n",
    "        pixel_values = self.image_processor(img, return_tensors='pt')['pixel_values'].squeeze(0)\n",
    "        labels = torch.zeros(len(STRESS_LABELS), dtype=torch.float32)\n",
    "        labels[int(row['label'])] = 1.0\n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'labels': labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "text_train, text_val = train_test_split(text_df, test_size=0.2, random_state=config.seed)\n",
    "image_train, image_val = train_test_split(image_df, test_size=0.2, random_state=config.seed)\n",
    "\n",
    "# Create datasets\n",
    "text_train_ds = TextDataset(text_train, tokenizer, config.max_seq_length)\n",
    "text_val_ds = TextDataset(text_val, tokenizer, config.max_seq_length)\n",
    "image_train_ds = ImageDataset(image_train, image_processor)\n",
    "image_val_ds = ImageDataset(image_val, image_processor)\n",
    "\n",
    "# Create data loaders\n",
    "text_train_loader = DataLoader(text_train_ds, batch_size=config.batch_size, shuffle=True)\n",
    "text_val_loader = DataLoader(text_val_ds, batch_size=config.batch_size)\n",
    "image_train_loader = DataLoader(image_train_ds, batch_size=config.batch_size, shuffle=True)\n",
    "image_val_loader = DataLoader(image_val_ds, batch_size=config.batch_size)\n",
    "\n",
    "print(f\"Text: {len(text_train_ds)} train, {len(text_val_ds)} val\")\n",
    "print(f\"Images: {len(image_train_ds)} train, {len(image_val_ds)} val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    \"\"\"LLM-based text classifier using DistilBERT\"\"\"\n",
    "    def __init__(self, num_labels=5, model_name='distilbert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        hidden_size = self.encoder.config.hidden_size\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(pooled)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        return {'loss': loss, 'logits': logits}\n",
    "\n",
    "class VisionClassifier(nn.Module):\n",
    "    \"\"\"ViT-based image classifier\"\"\"\n",
    "    def __init__(self, num_labels=5, model_name='google/vit-base-patch16-224'):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        hidden_size = self.encoder.config.hidden_size\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        outputs = self.encoder(pixel_values=pixel_values)\n",
    "        pooled = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(pooled)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        return {'loss': loss, 'logits': logits}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, device, model_type='text'):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, desc='Training', leave=False):\n",
    "        optimizer.zero_grad()\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "        if model_type == 'text':\n",
    "            outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n",
    "        else:\n",
    "            outputs = model(pixel_values=batch['pixel_values'], labels=batch['labels'])\n",
    "        loss = outputs['loss']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device, model_type='text'):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "            if model_type == 'text':\n",
    "                outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "            else:\n",
    "                outputs = model(pixel_values=batch['pixel_values'])\n",
    "            preds = torch.sigmoid(outputs['logits']) > 0.5\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(batch['labels'].cpu())\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    f1 = f1_score(all_labels.numpy(), all_preds.numpy(), average='macro', zero_division=0)\n",
    "    return {'f1': f1}\n",
    "\n",
    "def train_model(model, train_loader, val_loader, config, device, model_type='text'):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    best_f1 = 0\n",
    "    for epoch in range(config.epochs):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device, model_type)\n",
    "        metrics = evaluate(model, val_loader, device, model_type)\n",
    "        print(f\"  Epoch {epoch+1}/{config.epochs} - Loss: {train_loss:.4f} - F1: {metrics['f1']:.4f}\")\n",
    "        if metrics['f1'] > best_f1:\n",
    "            best_f1 = metrics['f1']\n",
    "    return best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train LLM (DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TRAINING LLM (DistilBERT)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "llm_model = TextClassifier(num_labels=config.num_labels).to(device)\n",
    "llm_f1 = train_model(llm_model, text_train_loader, text_val_loader, config, device, 'text')\n",
    "print(f\"\\nLLM Final F1: {llm_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TRAINING ViT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "vit_model = VisionClassifier(num_labels=config.num_labels).to(device)\n",
    "vit_f1 = train_model(vit_model, image_train_loader, image_val_loader, config, device, 'vision')\n",
    "print(f\"\\nViT Final F1: {vit_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_train(model_class, model_kwargs, train_datasets, val_loader, config, device, model_type='text'):\n",
    "    \"\"\"Federated learning with FedAvg\"\"\"\n",
    "    global_model = model_class(**model_kwargs).to(device)\n",
    "    global_state = global_model.state_dict()\n",
    "    \n",
    "    for round_idx in range(config.fed_rounds):\n",
    "        print(f\"  [Fed Round {round_idx+1}/{config.fed_rounds}]\")\n",
    "        client_states, client_sizes = [], []\n",
    "        \n",
    "        for client_idx, client_dataset in enumerate(train_datasets):\n",
    "            local_model = model_class(**model_kwargs).to(device)\n",
    "            local_model.load_state_dict(global_state)\n",
    "            client_loader = DataLoader(client_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "            optimizer = torch.optim.AdamW(local_model.parameters(), lr=config.learning_rate)\n",
    "            \n",
    "            for _ in range(config.local_epochs):\n",
    "                train_epoch(local_model, client_loader, optimizer, device, model_type)\n",
    "            \n",
    "            client_states.append(local_model.state_dict())\n",
    "            client_sizes.append(len(client_dataset))\n",
    "        \n",
    "        # FedAvg aggregation\n",
    "        total_size = sum(client_sizes)\n",
    "        for key in global_state.keys():\n",
    "            global_state[key] = sum(\n",
    "                client_states[i][key] * (client_sizes[i] / total_size)\n",
    "                for i in range(len(client_states))\n",
    "            )\n",
    "        \n",
    "        global_model.load_state_dict(global_state)\n",
    "        metrics = evaluate(global_model, val_loader, device, model_type)\n",
    "        print(f\"    Global F1: {metrics['f1']:.4f}\")\n",
    "    \n",
    "    return metrics['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FEDERATED LEARNING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Split data into clients\n",
    "n_clients = config.num_clients\n",
    "text_client_dfs = np.array_split(text_train, n_clients)\n",
    "text_client_datasets = [TextDataset(df, tokenizer, config.max_seq_length) for df in text_client_dfs]\n",
    "\n",
    "image_client_dfs = np.array_split(image_train, n_clients)\n",
    "image_client_datasets = [ImageDataset(df, image_processor) for df in image_client_dfs]\n",
    "\n",
    "print(f\"\\n[Federated LLM]\")\n",
    "fed_llm_f1 = federated_train(\n",
    "    TextClassifier, {'num_labels': config.num_labels},\n",
    "    text_client_datasets, text_val_loader, config, device, 'text'\n",
    ")\n",
    "\n",
    "print(f\"\\n[Federated ViT]\")\n",
    "fed_vit_f1 = federated_train(\n",
    "    VisionClassifier, {'num_labels': config.num_labels},\n",
    "    image_client_datasets, image_val_loader, config, device, 'vision'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results = {\n",
    "    'LLM_centralized': llm_f1,\n",
    "    'ViT_centralized': vit_f1,\n",
    "    'LLM_federated': fed_llm_f1,\n",
    "    'ViT_federated': fed_vit_f1,\n",
    "}\n",
    "\n",
    "print(\"\\n[Centralized Training]\")\n",
    "print(f\"  LLM (DistilBERT): F1 = {llm_f1:.4f}\")\n",
    "print(f\"  ViT: F1 = {vit_f1:.4f}\")\n",
    "\n",
    "print(\"\\n[Federated Training]\")\n",
    "print(f\"  LLM: F1 = {fed_llm_f1:.4f}\")\n",
    "print(f\"  ViT: F1 = {fed_vit_f1:.4f}\")\n",
    "\n",
    "print(\"\\n[Centralized vs Federated Gap]\")\n",
    "print(f\"  LLM: {llm_f1 - fed_llm_f1:+.4f}\")\n",
    "print(f\"  ViT: {vit_f1 - fed_vit_f1:+.4f}\")\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "with open('training_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"\\nResults saved to training_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Demo Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DEMO INFERENCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "llm_model.eval()\n",
    "\n",
    "demo_texts = [\n",
    "    \"The maize plants show severe wilting and the leaves are curling due to lack of water.\",\n",
    "    \"Tomato leaves display yellow spots and pale green coloration indicating nitrogen deficiency.\",\n",
    "    \"Small holes visible on cabbage leaves with evidence of caterpillar feeding damage.\",\n",
    "    \"White powdery coating on grape leaves suggests fungal infection.\",\n",
    "    \"Leaf edges appear brown and scorched after the recent heat wave.\",\n",
    "]\n",
    "\n",
    "for text in demo_texts:\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=128, truncation=True, padding='max_length')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = llm_model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "        probs = torch.sigmoid(outputs['logits']).squeeze()\n",
    "    \n",
    "    print(f\"\\nInput: {text[:70]}...\")\n",
    "    print(\"Predictions:\")\n",
    "    for idx, (label, prob) in enumerate(zip(STRESS_LABELS, probs)):\n",
    "        bar = \"#\" * int(prob * 20)\n",
    "        print(f\"  {label:15s} [{bar:20s}] {prob:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "You have successfully trained:\n",
    "- LLM (DistilBERT) for text-based crop stress classification\n",
    "- ViT for image-based crop stress classification\n",
    "- Federated versions of both models\n",
    "\n",
    "The models can now predict 5 types of crop stress:\n",
    "1. Water Stress\n",
    "2. Nutrient Deficiency\n",
    "3. Pest Risk\n",
    "4. Disease Risk\n",
    "5. Heat Stress"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
